"""
Quick test script to validate the improvements made to the AI training system.
This will run a short training session to test the new configuration.
"""

import sys
sys.path.append('.')

from main_modern import *
from modern_example_usage import ModernGenerator
from improved_helperAI import ModernTextProcessor

def quick_test():
    print("ğŸ§ª TESTING IMPROVED CONFIGURATION")
    print("=" * 50)
    print(f"ğŸ“Š New Settings:")
    print(f"   ğŸ¯ Tokenizer: {TOKENIZER_TYPE} (was: gpt2)")  
    print(f"   ğŸ“š Max Vocab: {MAX_VOCAB_SIZE} (was: 10000)")
    print(f"   ğŸ“ Context Window: {CONTEXT_WINDOW} (was: 64)")
    print(f"   ğŸ“ Batch Size: {BATCH_SIZE} (was: 16)")
    print(f"   ğŸ§  Model Dims: {EMBEDDING_DIM}/{HIDDEN_DIM} (was: 256/512)")
    print(f"   ğŸ­ Temperature: {TEMPERATURE} (was: 0.8)")
    print(f"   ğŸ”„ Repetition Penalty: {REPETITION_PENALTY} (new)")
    print()

    # Test preprocessing
    print("1ï¸âƒ£ Testing preprocessing...")
    preprocessed_data = preprocess_got_data()
    if preprocessed_data:
        print(f"   âœ… Vocabulary size: {len(preprocessed_data['vocab_to_int'])}")
        print(f"   âœ… Sequences: {len(preprocessed_data['sequences'])}")
    else:
        print("   âŒ Preprocessing failed!")
        return

    # Test data preparation
    print("\n2ï¸âƒ£ Testing data preparation...")
    train_loader = prepare_training_data(preprocessed_data)
    if train_loader:
        print(f"   âœ… Training batches: {len(train_loader)}")
    else:
        print("   âŒ Data preparation failed!")
        return

    # Test model creation
    print("\n3ï¸âƒ£ Testing model creation...")
    model, vocab_size, characters = create_ai_model(preprocessed_data)
    if model:
        print(f"   âœ… Model created with {vocab_size} vocab size")
    else:
        print("   âŒ Model creation failed!")
        return

    # Test generator
    print("\n4ï¸âƒ£ Testing generator...")
    try:
        generator = ModernGenerator(
            model=model,
            vocab_to_int=preprocessed_data["vocab_to_int"],
            int_to_vocab=preprocessed_data["int_to_vocab"],
            character_vocab=preprocessed_data["character_vocab"],
            tokenizer=ModernTextProcessor(TOKENIZER_TYPE, MODEL_NAME).tokenizer,
        )
        print("   âœ… Generator created successfully")
    except Exception as e:
        print(f"   âŒ Generator creation failed: {e}")
        return
    
    # Test generation with new parameters
    print("\n5ï¸âƒ£ Testing generation with new parameters...")
    try:
        # Test with proper character tag format
        sample = generator.generate_nucleus_sampling(
            seed_text="<TYRION LANNISTER>",
            max_length=80,
            top_p=TOP_P,
            temperature=TEMPERATURE,
            character="tyrion lannister",
            repetition_penalty=REPETITION_PENALTY
        )
        print(f"   ğŸ“ Sample 1: {sample}")
        
        # Test with another character
        sample2 = generator.generate_nucleus_sampling(
            seed_text="<JON SNOW>",
            max_length=80,
            top_p=TOP_P,
            temperature=TEMPERATURE,
            character="jon snow",
            repetition_penalty=REPETITION_PENALTY
        )
        print(f"   ğŸ“ Sample 2: {sample2}")
        
    except Exception as e:
        print(f"   âŒ Generation error: {e}")

    print(f"\nâœ… Configuration test completed!")

if __name__ == "__main__":
    quick_test()
